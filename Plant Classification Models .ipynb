{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd54e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image \n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f19059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'dataset/color600'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54941d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the information about the images\n",
    "\n",
    "data = [] # data placeholder for the dataframe\n",
    "dataset = [] # filled later with color, grayscale or segmented\n",
    "\n",
    "\n",
    "# now we walk down the entire file tree\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "\n",
    "    #print(\"record: root=\",root,\" dir=\",dirs,\" files=\",files)\n",
    "\n",
    "    if dirs: \n",
    "    \n",
    "        # we must be in one of the dataset-subfolders (/dataset, /dataset/color, /dataset/grayscale or /dataset/segmented)\n",
    "  \n",
    "        # extract the dataset type from the path\n",
    "        if root.endswith(('color', 'grayscale', 'segmented')):\n",
    "            dataset = root.split('/')[-1]\n",
    "\n",
    "    if not dirs and files: \n",
    "    \n",
    "        # we must be in one of the leaf folders containing the images\n",
    "\n",
    "        # extract the image metadata from path\n",
    "        subfolder_name = root.split('/')[-1]\n",
    "        plant_parts = subfolder_name.split('___')\n",
    "        species = plant_parts[0]\n",
    "        disease = plant_parts[1]\n",
    "\n",
    "        # filter down to only JPG, JPEG and PNG\n",
    "        image_files = [i for i in files if i.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "        # for each image file generate one new dataframe row\n",
    "        for filename in image_files:\n",
    "            data.append([filename, root, dataset, species, disease])\n",
    "\n",
    "# create dataframe from data array\n",
    "df = pd.DataFrame(data, columns =['filename', 'path', 'dataset', 'species', 'disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e9c1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species                           disease                             \n",
       "color600\\Apple                    Apple_scab                              600\n",
       "                                  Black_rot                               600\n",
       "                                  Cedar_apple_rust                        600\n",
       "                                  healthy                                 600\n",
       "color600\\Cherry_(including_sour)  Powdery_mildew                          600\n",
       "                                  healthy                                 600\n",
       "color600\\Corn_(maize)             Cercospora_leaf_spot Gray_leaf_spot     600\n",
       "                                  Common_rust_                            600\n",
       "                                  Northern_Leaf_Blight                    600\n",
       "                                  healthy                                 600\n",
       "color600\\Grape                    Black_rot                               600\n",
       "                                  Esca_(Black_Measles)                    600\n",
       "                                  Leaf_blight_(Isariopsis_Leaf_Spot)      600\n",
       "                                  healthy                                 600\n",
       "color600\\Peach                    Bacterial_spot                          600\n",
       "                                  healthy                                 600\n",
       "color600\\Pepper,_bell             Bacterial_spot                          600\n",
       "                                  healthy                                 600\n",
       "color600\\Potato                   Early_blight                            600\n",
       "                                  Late_blight                             600\n",
       "                                  healthy                                 600\n",
       "color600\\Strawberry               Leaf_scorch                             600\n",
       "                                  healthy                                 600\n",
       "color600\\Tomato                   Bacterial_spot                          600\n",
       "                                  Early_blight                            600\n",
       "                                  Late_blight                             600\n",
       "                                  Leaf_Mold                               600\n",
       "                                  Septoria_leaf_spot                      600\n",
       "                                  Spider_mites Two-spotted_spider_mite    600\n",
       "                                  Target_Spot                             600\n",
       "                                  Tomato_Yellow_Leaf_Curl_Virus           600\n",
       "                                  Tomato_mosaic_virus                     600\n",
       "                                  healthy                                 600\n",
       "Name: filename, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the classes of the data\n",
    "df.groupby(by=[\"species\", \"disease\"])['filename'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6652ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the images path\n",
    "image_path = 'dataset/color600'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066b3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the images and save them in a array\n",
    "# converts the images to grayscale and resizes them to (28,28,1) for LeNet model\n",
    "# without regularization\n",
    "\n",
    "X = [] # stores the image \n",
    "y = [] # stores the plants class\n",
    "diseases = [] #stores the diseases of the plants\n",
    "\n",
    "for folder_name, _,filenames in os.walk(image_path):\n",
    "    if folder_name !=\"dataset/color\" and '.DS_Store' not in filenames:\n",
    "        for file in filenames:\n",
    "            if file != 'desktop.ini':\n",
    "                file_path = folder_name +\"/\"+ file\n",
    "                image = Image.open(file_path)\n",
    "                image = image.convert('L') # converts images to grayscale\n",
    "                image = np.array(image.resize((28,28))) #resizes images to (28,28)\n",
    "                X.append(image)\n",
    "                y.append(os.path.basename(folder_name.split('\\\\')[1].split('___')[0]))\n",
    "                diseases.append(os.path.basename(folder_name.split('\\\\')[1]))\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Encoding the labels\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_le = le.fit_transform(y)\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_le, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b310ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 3.5769 - accuracy: 0.3091 - val_loss: 1.6242 - val_accuracy: 0.4475\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.5527 - accuracy: 0.4679 - val_loss: 1.3592 - val_accuracy: 0.5242\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.3629 - accuracy: 0.5271 - val_loss: 1.2990 - val_accuracy: 0.5598\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.2407 - accuracy: 0.5719 - val_loss: 1.1002 - val_accuracy: 0.6217\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.1426 - accuracy: 0.6026 - val_loss: 1.1290 - val_accuracy: 0.6076\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.0903 - accuracy: 0.6227 - val_loss: 1.0597 - val_accuracy: 0.6399\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 1.0347 - accuracy: 0.6419 - val_loss: 0.9788 - val_accuracy: 0.6674\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.9744 - accuracy: 0.6624 - val_loss: 0.9180 - val_accuracy: 0.6854\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.9389 - accuracy: 0.6710 - val_loss: 0.9413 - val_accuracy: 0.6664\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.9084 - accuracy: 0.6838 - val_loss: 0.9217 - val_accuracy: 0.6891\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.8670 - accuracy: 0.6988 - val_loss: 0.8660 - val_accuracy: 0.7045\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.8164 - accuracy: 0.7223 - val_loss: 0.8559 - val_accuracy: 0.7038\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.7796 - accuracy: 0.7280 - val_loss: 0.8429 - val_accuracy: 0.7073\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.7444 - accuracy: 0.7403 - val_loss: 0.8053 - val_accuracy: 0.7205\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.7172 - accuracy: 0.7512 - val_loss: 0.7834 - val_accuracy: 0.7348\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.7094 - accuracy: 0.7515 - val_loss: 0.8257 - val_accuracy: 0.7237\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.6924 - accuracy: 0.7583 - val_loss: 0.7757 - val_accuracy: 0.7427\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.6430 - accuracy: 0.7741 - val_loss: 0.7732 - val_accuracy: 0.7341\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.6369 - accuracy: 0.7782 - val_loss: 0.7524 - val_accuracy: 0.7472\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.5887 - accuracy: 0.7924 - val_loss: 0.6954 - val_accuracy: 0.7672\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.5514 - accuracy: 0.8071 - val_loss: 0.7537 - val_accuracy: 0.7485\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.5392 - accuracy: 0.8141 - val_loss: 0.7572 - val_accuracy: 0.7551\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.5350 - accuracy: 0.8146 - val_loss: 0.7178 - val_accuracy: 0.7636\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4931 - accuracy: 0.8278 - val_loss: 0.7752 - val_accuracy: 0.7545\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4675 - accuracy: 0.8352 - val_loss: 0.7064 - val_accuracy: 0.7745\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4579 - accuracy: 0.8395 - val_loss: 0.7118 - val_accuracy: 0.7659\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4392 - accuracy: 0.8439 - val_loss: 0.7467 - val_accuracy: 0.7646\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4151 - accuracy: 0.8523 - val_loss: 0.7383 - val_accuracy: 0.7677\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4023 - accuracy: 0.8593 - val_loss: 0.7185 - val_accuracy: 0.7699\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3914 - accuracy: 0.8621 - val_loss: 0.7484 - val_accuracy: 0.7775\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3575 - accuracy: 0.8737 - val_loss: 0.7409 - val_accuracy: 0.7763\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3582 - accuracy: 0.8751 - val_loss: 0.7369 - val_accuracy: 0.7803\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3715 - accuracy: 0.8684 - val_loss: 0.8060 - val_accuracy: 0.7626\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3612 - accuracy: 0.8730 - val_loss: 0.7261 - val_accuracy: 0.7806\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3331 - accuracy: 0.8821 - val_loss: 0.7115 - val_accuracy: 0.7884\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3145 - accuracy: 0.8882 - val_loss: 0.7543 - val_accuracy: 0.7884\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3081 - accuracy: 0.8918 - val_loss: 0.7827 - val_accuracy: 0.7783\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3134 - accuracy: 0.8893 - val_loss: 0.7966 - val_accuracy: 0.7773\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2820 - accuracy: 0.8999 - val_loss: 0.7392 - val_accuracy: 0.7927\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2793 - accuracy: 0.9037 - val_loss: 0.7633 - val_accuracy: 0.7896\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2616 - accuracy: 0.9086 - val_loss: 0.7816 - val_accuracy: 0.7934\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2664 - accuracy: 0.9028 - val_loss: 0.7776 - val_accuracy: 0.7879\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2775 - accuracy: 0.9014 - val_loss: 0.8169 - val_accuracy: 0.7914\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2458 - accuracy: 0.9121 - val_loss: 0.7830 - val_accuracy: 0.7927\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2411 - accuracy: 0.9162 - val_loss: 0.8700 - val_accuracy: 0.7775\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2323 - accuracy: 0.9185 - val_loss: 0.8365 - val_accuracy: 0.7843\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2252 - accuracy: 0.9229 - val_loss: 0.7758 - val_accuracy: 0.7970\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2113 - accuracy: 0.9254 - val_loss: 0.7865 - val_accuracy: 0.8015\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2208 - accuracy: 0.9207 - val_loss: 0.8255 - val_accuracy: 0.7854\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2140 - accuracy: 0.9232 - val_loss: 0.8705 - val_accuracy: 0.7813\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2129 - accuracy: 0.9256 - val_loss: 0.8180 - val_accuracy: 0.7934\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1832 - accuracy: 0.9344 - val_loss: 0.8397 - val_accuracy: 0.7992\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1952 - accuracy: 0.9323 - val_loss: 0.9476 - val_accuracy: 0.7717\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1898 - accuracy: 0.9347 - val_loss: 0.8218 - val_accuracy: 0.7982\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1815 - accuracy: 0.9324 - val_loss: 0.8794 - val_accuracy: 0.7957\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1775 - accuracy: 0.9379 - val_loss: 0.8812 - val_accuracy: 0.7866\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1683 - accuracy: 0.9409 - val_loss: 0.8704 - val_accuracy: 0.7977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1514 - accuracy: 0.9461 - val_loss: 0.8125 - val_accuracy: 0.8124\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1607 - accuracy: 0.9475 - val_loss: 0.8514 - val_accuracy: 0.7960\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1680 - accuracy: 0.9413 - val_loss: 0.8785 - val_accuracy: 0.7982\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1422 - accuracy: 0.9492 - val_loss: 0.8797 - val_accuracy: 0.8066\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1519 - accuracy: 0.9482 - val_loss: 0.9048 - val_accuracy: 0.7949\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1483 - accuracy: 0.9475 - val_loss: 0.8973 - val_accuracy: 0.8013\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1650 - accuracy: 0.9420 - val_loss: 0.9272 - val_accuracy: 0.7939\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1525 - accuracy: 0.9475 - val_loss: 0.9256 - val_accuracy: 0.7995\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1503 - accuracy: 0.9472 - val_loss: 0.8830 - val_accuracy: 0.8013\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1589 - accuracy: 0.9446 - val_loss: 0.9268 - val_accuracy: 0.8073\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1386 - accuracy: 0.9511 - val_loss: 0.9091 - val_accuracy: 0.8086\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1388 - accuracy: 0.9520 - val_loss: 0.9701 - val_accuracy: 0.7967\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1240 - accuracy: 0.9564 - val_loss: 0.9116 - val_accuracy: 0.8164\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1151 - accuracy: 0.9600 - val_loss: 0.9811 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1250 - accuracy: 0.9580 - val_loss: 0.9718 - val_accuracy: 0.7985\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1296 - accuracy: 0.9562 - val_loss: 0.9271 - val_accuracy: 0.8063\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1094 - accuracy: 0.9633 - val_loss: 1.0163 - val_accuracy: 0.7965\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1219 - accuracy: 0.9592 - val_loss: 0.9222 - val_accuracy: 0.8152\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1094 - accuracy: 0.9614 - val_loss: 0.9608 - val_accuracy: 0.8141\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1185 - accuracy: 0.9609 - val_loss: 0.9385 - val_accuracy: 0.8008\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1165 - accuracy: 0.9597 - val_loss: 1.0097 - val_accuracy: 0.7972\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1242 - accuracy: 0.9586 - val_loss: 1.0059 - val_accuracy: 0.8015\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1136 - accuracy: 0.9644 - val_loss: 1.0088 - val_accuracy: 0.8129\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1211 - accuracy: 0.9600 - val_loss: 0.9939 - val_accuracy: 0.7997\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0962 - accuracy: 0.9653 - val_loss: 0.9753 - val_accuracy: 0.8207\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0930 - accuracy: 0.9680 - val_loss: 0.9773 - val_accuracy: 0.8091\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1098 - accuracy: 0.9623 - val_loss: 0.9719 - val_accuracy: 0.8071\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0968 - accuracy: 0.9674 - val_loss: 0.9888 - val_accuracy: 0.8114\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1148 - accuracy: 0.9617 - val_loss: 1.0465 - val_accuracy: 0.8028\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0967 - accuracy: 0.9679 - val_loss: 0.9404 - val_accuracy: 0.8167\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0988 - accuracy: 0.9674 - val_loss: 0.9684 - val_accuracy: 0.8096\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1342 - accuracy: 0.9578 - val_loss: 0.9970 - val_accuracy: 0.8119\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0802 - accuracy: 0.9735 - val_loss: 1.0180 - val_accuracy: 0.8081\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0828 - accuracy: 0.9705 - val_loss: 1.0319 - val_accuracy: 0.8098\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1133 - accuracy: 0.9633 - val_loss: 0.9895 - val_accuracy: 0.8076\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0828 - accuracy: 0.9712 - val_loss: 1.0354 - val_accuracy: 0.8139\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0909 - accuracy: 0.9706 - val_loss: 1.0083 - val_accuracy: 0.8106\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1032 - accuracy: 0.9652 - val_loss: 1.0065 - val_accuracy: 0.8051\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0845 - accuracy: 0.9708 - val_loss: 1.0669 - val_accuracy: 0.8071\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0899 - accuracy: 0.9705 - val_loss: 1.0367 - val_accuracy: 0.8088\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0782 - accuracy: 0.9724 - val_loss: 1.0313 - val_accuracy: 0.8058\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0913 - accuracy: 0.9702 - val_loss: 1.0565 - val_accuracy: 0.8061\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0858 - accuracy: 0.9727 - val_loss: 1.0790 - val_accuracy: 0.8043\n"
     ]
    }
   ],
   "source": [
    "# Model LeNet for plant classification without regularization\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model_le1 = Sequential()\n",
    "\n",
    "model_le1.add(Conv2D(filters = 126,\n",
    "                     input_shape = (28,28,1),\n",
    "                     kernel_size = (5,5),\n",
    "                     activation = 'relu'))\n",
    "\n",
    "model_le1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model_le1.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model_le1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model_le1.add(Dropout(rate = 0.2))\n",
    "\n",
    "model_le1.add(Flatten())\n",
    "\n",
    "model_le1.add(Dense(units = 128,\n",
    "                    activation = 'relu'))\n",
    "\n",
    "model_le1.add(Dense(units = 9,\n",
    "                     activation='softmax'))\n",
    "\n",
    "model_le1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_le1_history = model_le1.fit(X_train, y_train, batch_size=200, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645e93c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.66       449\n",
      "           1       0.85      0.72      0.78       258\n",
      "           2       0.92      0.94      0.93       486\n",
      "           3       0.93      0.95      0.94       503\n",
      "           4       0.82      0.74      0.78       253\n",
      "           5       0.72      0.69      0.70       252\n",
      "           6       0.67      0.71      0.69       363\n",
      "           7       0.82      0.56      0.67       235\n",
      "           8       0.81      0.87      0.84      1161\n",
      "\n",
      "    accuracy                           0.80      3960\n",
      "   macro avg       0.80      0.76      0.78      3960\n",
      "weighted avg       0.81      0.80      0.80      3960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>187</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>173</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>259</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>132</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7     8\n",
       "Real                                                   \n",
       "0          301   16    7    6    9   11   41    2    56\n",
       "1           20  187    6    3    4    1   11    1    25\n",
       "2           13    1  455    0    2    1    1    0    13\n",
       "3            5    0    1  476    0    2    2    0    17\n",
       "4           11    2    7    1  187    1    5    0    39\n",
       "5           14    5    1    1    4  173   23    1    30\n",
       "6           26    6    0    1    2   18  259   19    32\n",
       "7           25    1    5   10    2    6   29  132    25\n",
       "8           53    3   10   12   18   27   17    6  1015"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LeNet no regularization\n",
    "# predicting the plats of the test set\n",
    "y_pred_model_le1 = model_le1.predict(X_test)\n",
    "\n",
    "\n",
    "# getting the Plant with highest probabilty \n",
    "y_pred = np.argmax(y_pred_model_le1, axis=1)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18728e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the images and save them in a array\n",
    "# converts the images to grayscale and resizes them to (28,28,1) for LeNet model\n",
    "# MinMax binary regularization\n",
    "\n",
    "X = [] # stores the image \n",
    "y = [] # stores the plants class\n",
    "diseases = [] #stores the diseases of the plants\n",
    "\n",
    "for folder_name, _,filenames in os.walk(image_path):\n",
    "    if folder_name !=\"dataset/color\" and '.DS_Store' not in filenames:\n",
    "        for file in filenames:\n",
    "            if file != 'desktop.ini':\n",
    "                file_path = folder_name +\"/\"+ file\n",
    "                image = Image.open(file_path)\n",
    "                image = image.convert('L') # converts images to grayscale\n",
    "                image = np.array(image.resize((28,28))) #resizes images to (28,28)\n",
    "                ret, thresh = cv2.threshold(image,140,255,cv2.THRESH_BINARY)\n",
    "                image = cv2.normalize(thresh, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                X.append(image)\n",
    "                y.append(os.path.basename(folder_name.split('\\\\')[1].split('___')[0]))\n",
    "                diseases.append(os.path.basename(folder_name.split('\\\\')[1]))\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Encoding the labels\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_le = le.fit_transform(y)\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_le, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1306afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 9s 103ms/step - loss: 1.6416 - accuracy: 0.4443 - val_loss: 1.4374 - val_accuracy: 0.5053\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 1.2947 - accuracy: 0.5574 - val_loss: 1.2138 - val_accuracy: 0.5813\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 1.1500 - accuracy: 0.5996 - val_loss: 1.1589 - val_accuracy: 0.6015\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 1.0542 - accuracy: 0.6374 - val_loss: 1.0899 - val_accuracy: 0.6187\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.9760 - accuracy: 0.6607 - val_loss: 1.0443 - val_accuracy: 0.6407\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.9183 - accuracy: 0.6779 - val_loss: 1.0268 - val_accuracy: 0.6419\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.8583 - accuracy: 0.7001 - val_loss: 1.0002 - val_accuracy: 0.6551\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.8184 - accuracy: 0.7123 - val_loss: 0.9976 - val_accuracy: 0.6672\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.7623 - accuracy: 0.7338 - val_loss: 0.9871 - val_accuracy: 0.6662\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.7279 - accuracy: 0.7444 - val_loss: 0.9515 - val_accuracy: 0.6750\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.6890 - accuracy: 0.7588 - val_loss: 0.9936 - val_accuracy: 0.6664\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.6531 - accuracy: 0.7716 - val_loss: 0.9774 - val_accuracy: 0.6725\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.6198 - accuracy: 0.7826 - val_loss: 1.0023 - val_accuracy: 0.6775\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.5777 - accuracy: 0.7965 - val_loss: 0.9855 - val_accuracy: 0.6765\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.5506 - accuracy: 0.8090 - val_loss: 1.0016 - val_accuracy: 0.6768\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.5279 - accuracy: 0.8172 - val_loss: 1.0102 - val_accuracy: 0.6828\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4958 - accuracy: 0.8259 - val_loss: 1.0353 - val_accuracy: 0.6798\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4601 - accuracy: 0.8374 - val_loss: 1.0473 - val_accuracy: 0.6869\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4497 - accuracy: 0.8438 - val_loss: 1.0657 - val_accuracy: 0.6826\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4162 - accuracy: 0.8551 - val_loss: 1.0838 - val_accuracy: 0.6856\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3984 - accuracy: 0.8563 - val_loss: 1.0845 - val_accuracy: 0.6813\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3844 - accuracy: 0.8645 - val_loss: 1.1276 - val_accuracy: 0.6889\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3455 - accuracy: 0.8779 - val_loss: 1.1746 - val_accuracy: 0.6652\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3418 - accuracy: 0.8807 - val_loss: 1.1912 - val_accuracy: 0.6871\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3287 - accuracy: 0.8832 - val_loss: 1.2219 - val_accuracy: 0.6818\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3180 - accuracy: 0.8884 - val_loss: 1.1915 - val_accuracy: 0.6874\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2929 - accuracy: 0.8976 - val_loss: 1.2890 - val_accuracy: 0.6856\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2774 - accuracy: 0.9047 - val_loss: 1.2430 - val_accuracy: 0.6861\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2700 - accuracy: 0.9055 - val_loss: 1.2974 - val_accuracy: 0.6750\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2592 - accuracy: 0.9112 - val_loss: 1.3382 - val_accuracy: 0.6854\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2570 - accuracy: 0.9090 - val_loss: 1.3133 - val_accuracy: 0.6806\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2560 - accuracy: 0.9088 - val_loss: 1.3493 - val_accuracy: 0.6722\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2361 - accuracy: 0.9186 - val_loss: 1.3802 - val_accuracy: 0.6763\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2255 - accuracy: 0.9222 - val_loss: 1.4268 - val_accuracy: 0.6765\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2210 - accuracy: 0.9244 - val_loss: 1.4839 - val_accuracy: 0.6780\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2039 - accuracy: 0.9296 - val_loss: 1.4354 - val_accuracy: 0.6833\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2076 - accuracy: 0.9275 - val_loss: 1.5201 - val_accuracy: 0.6795\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2076 - accuracy: 0.9292 - val_loss: 1.5327 - val_accuracy: 0.6783\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1955 - accuracy: 0.9323 - val_loss: 1.5469 - val_accuracy: 0.6818\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1948 - accuracy: 0.9328 - val_loss: 1.5158 - val_accuracy: 0.6841\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1894 - accuracy: 0.9340 - val_loss: 1.5454 - val_accuracy: 0.6785\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1739 - accuracy: 0.9422 - val_loss: 1.5957 - val_accuracy: 0.6836\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1717 - accuracy: 0.9412 - val_loss: 1.5730 - val_accuracy: 0.6864\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1616 - accuracy: 0.9453 - val_loss: 1.6369 - val_accuracy: 0.6773\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1636 - accuracy: 0.9434 - val_loss: 1.6560 - val_accuracy: 0.6780\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1596 - accuracy: 0.9444 - val_loss: 1.7131 - val_accuracy: 0.6778\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1538 - accuracy: 0.9484 - val_loss: 1.6583 - val_accuracy: 0.6788\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1546 - accuracy: 0.9456 - val_loss: 1.7838 - val_accuracy: 0.6732\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1569 - accuracy: 0.9455 - val_loss: 1.8012 - val_accuracy: 0.6790\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1510 - accuracy: 0.9480 - val_loss: 1.7298 - val_accuracy: 0.6742\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1410 - accuracy: 0.9506 - val_loss: 1.8114 - val_accuracy: 0.6811\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1444 - accuracy: 0.9511 - val_loss: 1.7617 - val_accuracy: 0.6758\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1456 - accuracy: 0.9502 - val_loss: 1.7991 - val_accuracy: 0.6778\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1426 - accuracy: 0.9511 - val_loss: 1.7567 - val_accuracy: 0.6717\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1309 - accuracy: 0.9558 - val_loss: 1.8281 - val_accuracy: 0.6747\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1319 - accuracy: 0.9556 - val_loss: 1.8592 - val_accuracy: 0.6712\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1382 - accuracy: 0.9537 - val_loss: 1.8908 - val_accuracy: 0.6816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1308 - accuracy: 0.9559 - val_loss: 1.9108 - val_accuracy: 0.6760\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1317 - accuracy: 0.9554 - val_loss: 1.9136 - val_accuracy: 0.6811\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1320 - accuracy: 0.9534 - val_loss: 1.8677 - val_accuracy: 0.6816\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1237 - accuracy: 0.9583 - val_loss: 1.9476 - val_accuracy: 0.6763\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1224 - accuracy: 0.9577 - val_loss: 1.9613 - val_accuracy: 0.6846\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1217 - accuracy: 0.9598 - val_loss: 1.9375 - val_accuracy: 0.6715\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.1235 - accuracy: 0.9588 - val_loss: 1.9226 - val_accuracy: 0.6828\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1303 - accuracy: 0.9577 - val_loss: 1.9751 - val_accuracy: 0.6740\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1255 - accuracy: 0.9564 - val_loss: 1.9619 - val_accuracy: 0.6823\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1213 - accuracy: 0.9593 - val_loss: 1.9788 - val_accuracy: 0.6755\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1173 - accuracy: 0.9599 - val_loss: 1.9330 - val_accuracy: 0.6750\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1194 - accuracy: 0.9595 - val_loss: 2.0058 - val_accuracy: 0.6763\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1249 - accuracy: 0.9565 - val_loss: 2.0951 - val_accuracy: 0.6735\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1156 - accuracy: 0.9605 - val_loss: 2.0411 - val_accuracy: 0.6793\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1145 - accuracy: 0.9615 - val_loss: 2.0656 - val_accuracy: 0.6758\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1110 - accuracy: 0.9616 - val_loss: 2.0541 - val_accuracy: 0.6790\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1090 - accuracy: 0.9634 - val_loss: 2.0673 - val_accuracy: 0.6707\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1214 - accuracy: 0.9585 - val_loss: 2.1219 - val_accuracy: 0.6707\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1082 - accuracy: 0.9636 - val_loss: 2.1003 - val_accuracy: 0.6755\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1122 - accuracy: 0.9616 - val_loss: 2.1581 - val_accuracy: 0.6765\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.1153 - accuracy: 0.9618 - val_loss: 2.0737 - val_accuracy: 0.6699\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1099 - accuracy: 0.9631 - val_loss: 2.1887 - val_accuracy: 0.6553\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1171 - accuracy: 0.9609 - val_loss: 2.0562 - val_accuracy: 0.6722\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1057 - accuracy: 0.9649 - val_loss: 2.1551 - val_accuracy: 0.6710\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1020 - accuracy: 0.9653 - val_loss: 2.1597 - val_accuracy: 0.6826\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1027 - accuracy: 0.9657 - val_loss: 2.1824 - val_accuracy: 0.6717\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1036 - accuracy: 0.9643 - val_loss: 2.0827 - val_accuracy: 0.6707\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1105 - accuracy: 0.9618 - val_loss: 2.1977 - val_accuracy: 0.6601\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1046 - accuracy: 0.9649 - val_loss: 2.2349 - val_accuracy: 0.6699\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1059 - accuracy: 0.9649 - val_loss: 2.1427 - val_accuracy: 0.6775\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1003 - accuracy: 0.9657 - val_loss: 2.3069 - val_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0989 - accuracy: 0.9657 - val_loss: 2.1677 - val_accuracy: 0.6775\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0992 - accuracy: 0.9655 - val_loss: 2.2289 - val_accuracy: 0.6745\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1003 - accuracy: 0.9643 - val_loss: 2.1839 - val_accuracy: 0.6763\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0951 - accuracy: 0.9672 - val_loss: 2.3829 - val_accuracy: 0.6735\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0995 - accuracy: 0.9669 - val_loss: 2.2185 - val_accuracy: 0.6740\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0996 - accuracy: 0.9668 - val_loss: 2.2730 - val_accuracy: 0.6684\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0975 - accuracy: 0.9673 - val_loss: 2.2756 - val_accuracy: 0.6753\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0913 - accuracy: 0.9693 - val_loss: 2.3126 - val_accuracy: 0.6662\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0909 - accuracy: 0.9693 - val_loss: 2.3712 - val_accuracy: 0.6808\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0961 - accuracy: 0.9670 - val_loss: 2.3108 - val_accuracy: 0.6745\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0916 - accuracy: 0.9693 - val_loss: 2.4063 - val_accuracy: 0.6652\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0932 - accuracy: 0.9682 - val_loss: 2.3494 - val_accuracy: 0.6732\n"
     ]
    }
   ],
   "source": [
    "# Model LeNet for plant classification with MinMax norm with binary output regularization\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model_le2 = Sequential()\n",
    "\n",
    "model_le2.add(Conv2D(filters = 126,\n",
    "                     input_shape = (28,28,1),\n",
    "                     kernel_size = (5,5),\n",
    "                     activation = 'relu'))\n",
    "\n",
    "model_le2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model_le2.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model_le2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model_le2.add(Dropout(rate = 0.2))\n",
    "\n",
    "model_le2.add(Flatten())\n",
    "\n",
    "model_le2.add(Dense(units = 128,\n",
    "                    activation = 'relu'))\n",
    "\n",
    "model_le2.add(Dense(units = 9,\n",
    "                     activation='softmax'))\n",
    "\n",
    "model_le2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_le2_history = model_le2.fit(X_train, y_train, batch_size=200, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f4a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.43      0.45       449\n",
      "           1       0.64      0.56      0.60       258\n",
      "           2       0.81      0.85      0.83       486\n",
      "           3       0.84      0.84      0.84       503\n",
      "           4       0.58      0.56      0.57       253\n",
      "           5       0.64      0.62      0.63       252\n",
      "           6       0.57      0.44      0.50       363\n",
      "           7       0.63      0.52      0.57       235\n",
      "           8       0.68      0.78      0.73      1161\n",
      "\n",
      "    accuracy                           0.67      3960\n",
      "   macro avg       0.65      0.62      0.63      3960\n",
      "weighted avg       0.67      0.67      0.67      3960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>161</td>\n",
       "      <td>32</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>122</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8\n",
       "Real                                                  \n",
       "0          192   15   23   19   22   13   33    9  123\n",
       "1           25  144    7    2   15    7   12    4   42\n",
       "2           12    7  414    2   11    1    0    2   37\n",
       "3           14    0    1  425    3    7    7    9   37\n",
       "4           23    6   13    1  142    4    1    3   60\n",
       "5           20    6    7    6    3  157   20    1   32\n",
       "6           43   15    3   10    5   32  161   32   62\n",
       "7           16    7    5   12    3    7   26  122   37\n",
       "8           67   24   41   30   40   18   21   11  909"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LeNet MinMax binary regularization\n",
    "# predicting the the plants of the test set\n",
    "y_pred_model_le2 = model_le2.predict(X_test)\n",
    "\n",
    "# getting the Plant with highest probabilty \n",
    "y_pred = np.argmax(y_pred_model_le2, axis=1)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0efaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the images and save them in a array\n",
    "# converts the images to grayscale and resizes them to (28,28,1) for LeNet model\n",
    "# MinMax regularization\n",
    "\n",
    "X = [] # stores the image \n",
    "y = [] # stores the plants class\n",
    "diseases = [] #stores the diseases of the plants\n",
    "\n",
    "for folder_name, _,filenames in os.walk(image_path):\n",
    "    if folder_name !=\"dataset/color\" and '.DS_Store' not in filenames:\n",
    "        for file in filenames:\n",
    "            if file != 'desktop.ini':\n",
    "                file_path = folder_name +\"/\"+ file\n",
    "                image = Image.open(file_path)\n",
    "                image = image.convert('L') # converts images to grayscale\n",
    "                image = np.array(image.resize((28,28))) #resizes images to (28,28)\n",
    "                image= cv2.normalize(image, None, 0, 1.0,\n",
    "                                    cv2.NORM_MINMAX, dtype=cv2.CV_32F) # regularization\n",
    "                X.append(image)\n",
    "                y.append(os.path.basename(folder_name.split('\\\\')[1].split('___')[0]))\n",
    "                diseases.append(os.path.basename(folder_name.split('\\\\')[1]))\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Encoding the labels\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_le = le.fit_transform(y)\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_le, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc4bca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 9s 104ms/step - loss: 1.7051 - accuracy: 0.4133 - val_loss: 1.4184 - val_accuracy: 0.5119\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 1.2365 - accuracy: 0.5753 - val_loss: 1.1519 - val_accuracy: 0.6114\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 1.0474 - accuracy: 0.6415 - val_loss: 0.9914 - val_accuracy: 0.6646\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.9336 - accuracy: 0.6819 - val_loss: 0.9126 - val_accuracy: 0.6944\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.8309 - accuracy: 0.7142 - val_loss: 0.8108 - val_accuracy: 0.7237\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.7609 - accuracy: 0.7404 - val_loss: 0.7541 - val_accuracy: 0.7462\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.7113 - accuracy: 0.7592 - val_loss: 0.7444 - val_accuracy: 0.7482\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.6495 - accuracy: 0.7799 - val_loss: 0.7203 - val_accuracy: 0.7553\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.6213 - accuracy: 0.7859 - val_loss: 0.6644 - val_accuracy: 0.7763\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.5887 - accuracy: 0.7996 - val_loss: 0.6646 - val_accuracy: 0.7735\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.5371 - accuracy: 0.8184 - val_loss: 0.5882 - val_accuracy: 0.8023\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.5157 - accuracy: 0.8223 - val_loss: 0.6047 - val_accuracy: 0.7924\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4957 - accuracy: 0.8266 - val_loss: 0.7229 - val_accuracy: 0.7588\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4867 - accuracy: 0.8297 - val_loss: 0.6658 - val_accuracy: 0.7692\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4400 - accuracy: 0.8495 - val_loss: 0.5406 - val_accuracy: 0.8210\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.4055 - accuracy: 0.8604 - val_loss: 0.5474 - val_accuracy: 0.8154\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3953 - accuracy: 0.8646 - val_loss: 0.5577 - val_accuracy: 0.8096\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3753 - accuracy: 0.8691 - val_loss: 0.5312 - val_accuracy: 0.8212\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3497 - accuracy: 0.8782 - val_loss: 0.5601 - val_accuracy: 0.8088\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.3393 - accuracy: 0.8827 - val_loss: 0.5246 - val_accuracy: 0.8260\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3205 - accuracy: 0.8885 - val_loss: 0.5459 - val_accuracy: 0.8192\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.3033 - accuracy: 0.8941 - val_loss: 0.5103 - val_accuracy: 0.8341\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2882 - accuracy: 0.9022 - val_loss: 0.5211 - val_accuracy: 0.8361\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2671 - accuracy: 0.9062 - val_loss: 0.5189 - val_accuracy: 0.8316\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2668 - accuracy: 0.9080 - val_loss: 0.5322 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2370 - accuracy: 0.9182 - val_loss: 0.4959 - val_accuracy: 0.8490\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2343 - accuracy: 0.9187 - val_loss: 0.5122 - val_accuracy: 0.8328\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2279 - accuracy: 0.9208 - val_loss: 0.5422 - val_accuracy: 0.8409\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.2134 - accuracy: 0.9274 - val_loss: 0.5055 - val_accuracy: 0.8391\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.2043 - accuracy: 0.9277 - val_loss: 0.5084 - val_accuracy: 0.8467\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1846 - accuracy: 0.9360 - val_loss: 0.5031 - val_accuracy: 0.8470\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1859 - accuracy: 0.9341 - val_loss: 0.5216 - val_accuracy: 0.8432\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1690 - accuracy: 0.9431 - val_loss: 0.5336 - val_accuracy: 0.8449\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1649 - accuracy: 0.9412 - val_loss: 0.5161 - val_accuracy: 0.8422\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1649 - accuracy: 0.9423 - val_loss: 0.5328 - val_accuracy: 0.8402\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1550 - accuracy: 0.9466 - val_loss: 0.5333 - val_accuracy: 0.8414\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1525 - accuracy: 0.9461 - val_loss: 0.5711 - val_accuracy: 0.8409\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1335 - accuracy: 0.9527 - val_loss: 0.5242 - val_accuracy: 0.8497\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 0.1247 - accuracy: 0.9585 - val_loss: 0.5435 - val_accuracy: 0.8457\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1176 - accuracy: 0.9617 - val_loss: 0.5366 - val_accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1126 - accuracy: 0.9608 - val_loss: 0.5517 - val_accuracy: 0.8515\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1097 - accuracy: 0.9621 - val_loss: 0.5769 - val_accuracy: 0.8343\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.1078 - accuracy: 0.9643 - val_loss: 0.5554 - val_accuracy: 0.8490\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1026 - accuracy: 0.9664 - val_loss: 0.5872 - val_accuracy: 0.8457\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.1007 - accuracy: 0.9658 - val_loss: 0.5580 - val_accuracy: 0.8495\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0894 - accuracy: 0.9695 - val_loss: 0.5985 - val_accuracy: 0.8449\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1012 - accuracy: 0.9634 - val_loss: 0.5987 - val_accuracy: 0.8429\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0937 - accuracy: 0.9682 - val_loss: 0.6205 - val_accuracy: 0.8465\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0874 - accuracy: 0.9699 - val_loss: 0.6033 - val_accuracy: 0.8432\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.6223 - val_accuracy: 0.8437\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0744 - accuracy: 0.9739 - val_loss: 0.6259 - val_accuracy: 0.8472\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0783 - accuracy: 0.9742 - val_loss: 0.6159 - val_accuracy: 0.8422\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0721 - accuracy: 0.9753 - val_loss: 0.6060 - val_accuracy: 0.8525\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0694 - accuracy: 0.9778 - val_loss: 0.6041 - val_accuracy: 0.8508\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0614 - accuracy: 0.9802 - val_loss: 0.6238 - val_accuracy: 0.8477\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0678 - accuracy: 0.9778 - val_loss: 0.6230 - val_accuracy: 0.8417\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0726 - accuracy: 0.9762 - val_loss: 0.6367 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0771 - accuracy: 0.9731 - val_loss: 0.6351 - val_accuracy: 0.8460\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0632 - accuracy: 0.9808 - val_loss: 0.6359 - val_accuracy: 0.8465\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0603 - accuracy: 0.9802 - val_loss: 0.6245 - val_accuracy: 0.8510\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0635 - accuracy: 0.9782 - val_loss: 0.6286 - val_accuracy: 0.8439\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.6298 - val_accuracy: 0.8495\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0561 - accuracy: 0.9802 - val_loss: 0.6571 - val_accuracy: 0.8462\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0548 - accuracy: 0.9814 - val_loss: 0.6686 - val_accuracy: 0.8503\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.6613 - val_accuracy: 0.8480\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0558 - accuracy: 0.9814 - val_loss: 0.7685 - val_accuracy: 0.8407\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0596 - accuracy: 0.9804 - val_loss: 0.6707 - val_accuracy: 0.8429\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 0.6426 - val_accuracy: 0.8490\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 0.6571 - val_accuracy: 0.8538\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.7217 - val_accuracy: 0.8460\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0619 - accuracy: 0.9789 - val_loss: 0.6898 - val_accuracy: 0.8409\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0623 - accuracy: 0.9777 - val_loss: 0.7188 - val_accuracy: 0.8386\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0521 - accuracy: 0.9826 - val_loss: 0.7093 - val_accuracy: 0.8472\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.7335 - val_accuracy: 0.8465\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.6898 - val_accuracy: 0.8513\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.7160 - val_accuracy: 0.8505\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0411 - accuracy: 0.9857 - val_loss: 0.6671 - val_accuracy: 0.8543\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.7069 - val_accuracy: 0.8528\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.7467 - val_accuracy: 0.8490\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0402 - accuracy: 0.9857 - val_loss: 0.8117 - val_accuracy: 0.8374\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0456 - accuracy: 0.9833 - val_loss: 0.7140 - val_accuracy: 0.8515\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.7228 - val_accuracy: 0.8533\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0436 - accuracy: 0.9845 - val_loss: 0.7621 - val_accuracy: 0.8460\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 0.7530 - val_accuracy: 0.8323\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 0.7307 - val_accuracy: 0.8472\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0414 - accuracy: 0.9859 - val_loss: 0.6992 - val_accuracy: 0.8520\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0313 - accuracy: 0.9901 - val_loss: 0.7295 - val_accuracy: 0.8533\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.7561 - val_accuracy: 0.8495\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0344 - accuracy: 0.9888 - val_loss: 0.7503 - val_accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0299 - accuracy: 0.9901 - val_loss: 0.7751 - val_accuracy: 0.8470\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0436 - accuracy: 0.9852 - val_loss: 0.7646 - val_accuracy: 0.8417\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 0.0438 - accuracy: 0.9850 - val_loss: 0.7592 - val_accuracy: 0.8545\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.7622 - val_accuracy: 0.8525\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.7493 - val_accuracy: 0.8518\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 0.8098 - val_accuracy: 0.8470\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 0.7581 - val_accuracy: 0.8487\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.0393 - accuracy: 0.9852 - val_loss: 0.8269 - val_accuracy: 0.8492\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.7621 - val_accuracy: 0.8505\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 0.7793 - val_accuracy: 0.8508\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 0.8063 - val_accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Model LeNet for plant classification with MinMax norm regularization\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model_le3 = Sequential()\n",
    "\n",
    "model_le3.add(Conv2D(filters = 126,\n",
    "                     input_shape = (28,28,1),\n",
    "                     kernel_size = (5,5),\n",
    "                     activation = 'relu'))\n",
    "\n",
    "model_le3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model_le3.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model_le3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model_le3.add(Dropout(rate = 0.2))\n",
    "\n",
    "model_le3.add(Flatten())\n",
    "\n",
    "model_le3.add(Dense(units = 128,\n",
    "                    activation = 'relu'))\n",
    "\n",
    "model_le3.add(Dense(units = 9,\n",
    "                     activation='softmax'))\n",
    "\n",
    "model_le3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_le3_history = model_le3.fit(X_train, y_train, batch_size=200, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce851d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74       449\n",
      "           1       0.83      0.86      0.85       258\n",
      "           2       0.96      0.93      0.94       486\n",
      "           3       0.96      0.95      0.95       503\n",
      "           4       0.80      0.85      0.82       253\n",
      "           5       0.86      0.73      0.79       252\n",
      "           6       0.76      0.73      0.75       363\n",
      "           7       0.84      0.68      0.75       235\n",
      "           8       0.88      0.88      0.88      1161\n",
      "\n",
      "    accuracy                           0.85      3960\n",
      "   macro avg       0.84      0.83      0.83      3960\n",
      "weighted avg       0.85      0.85      0.85      3960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>266</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>160</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7     8\n",
       "Real                                                   \n",
       "0          370   14    5    0   11    1   15    5    28\n",
       "1           13  221    2    0    2    1    7    1    11\n",
       "2           16    6  451    0    6    1    0    0     6\n",
       "3            6    4    0  477    1    0    2    2    11\n",
       "4           16    2    3    0  214    2    0    0    16\n",
       "5           11    3    1    0    2  185   30    1    19\n",
       "6           34    7    0    1    5   11  266   12    27\n",
       "7           20    3    2    8    3    2   15  160    22\n",
       "8           61    5    5   10   23   11   15    9  1022"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LeNet MinMax regularization\n",
    "# predicting the the plants of the test set\n",
    "y_pred_model_le3 = model_le3.predict(X_test)\n",
    "\n",
    "# getting the Plant with highest probabilty \n",
    "y_pred = np.argmax(y_pred_model_le3, axis=1)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4add7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet MinMax norm regularization\n",
    "# import dataset as (227,227,3) with normalizing by dividing by 255\n",
    "## rounding to 3 digits because of memory limitations\n",
    "\n",
    "#convert the images and save them in a list. \n",
    "X = [] # stores the image \n",
    "y = [] # stores the plants class\n",
    "diseases = [] #stores the diseases of the plants\n",
    "\n",
    "for folder_name, _,filenames in os.walk(image_path):\n",
    "    if folder_name !=\"dataset/color600\" and '.DS_Store' not in filenames:\n",
    "        for file in filenames:\n",
    "            if file != 'desktop.ini':\n",
    "                file_path = folder_name +\"/\"+ file\n",
    "                image = Image.open(file_path)\n",
    "                image = np.array(image.convert('RGB'))\n",
    "                image = cv2.resize(image, (227,227))\n",
    "                image= cv2.normalize(image, None, 0, 1.0,cv2.NORM_MINMAX, dtype=cv2.CV_32F) # regularization\n",
    "                #image = image.resize((227,227)) # resizing the images to (227,227,3)\n",
    "                #image = np.round(image/255, 3) # regularization\n",
    "                #image= cv2.normalize(image, image, 0, 1.0,cv2.NORM_MINMAX, dtype=cv2.CV_32F) # regularization\n",
    "                X.append(image)\n",
    "                y.append(os.path.basename(folder_name.split('\\\\')[1].split('___')[0]))\n",
    "                diseases.append(os.path.basename(folder_name.split('\\\\')[1]))\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "X = np.array(X).astype('float32')\n",
    "\n",
    "# Encoding the labels\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y_le = le.fit_transform(y)\n",
    "y_le = np.array(y_le).astype('float32')\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_le, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051989a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "248/248 [==============================] - 374s 2s/step - loss: 4.6338 - accuracy: 0.5420 - val_loss: 3.0731 - val_accuracy: 0.4422\n",
      "Epoch 2/20\n",
      "248/248 [==============================] - 366s 1s/step - loss: 0.7612 - accuracy: 0.7556 - val_loss: 1.1328 - val_accuracy: 0.6520\n",
      "Epoch 3/20\n",
      "248/248 [==============================] - 369s 1s/step - loss: 0.5536 - accuracy: 0.8204 - val_loss: 1.6246 - val_accuracy: 0.5876\n",
      "Epoch 4/20\n",
      "248/248 [==============================] - 369s 1s/step - loss: 0.4175 - accuracy: 0.8664 - val_loss: 1.0214 - val_accuracy: 0.7528\n",
      "Epoch 5/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.3466 - accuracy: 0.8896 - val_loss: 2.7238 - val_accuracy: 0.5982\n",
      "Epoch 6/20\n",
      "248/248 [==============================] - 367s 1s/step - loss: 0.3071 - accuracy: 0.9061 - val_loss: 1.4435 - val_accuracy: 0.6684\n",
      "Epoch 7/20\n",
      "248/248 [==============================] - 369s 1s/step - loss: 0.2885 - accuracy: 0.9136 - val_loss: 3.3770 - val_accuracy: 0.6053\n",
      "Epoch 8/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.2857 - accuracy: 0.9183 - val_loss: 6.3585 - val_accuracy: 0.4932\n",
      "Epoch 9/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.3631 - accuracy: 0.8994 - val_loss: 7.1032 - val_accuracy: 0.5601\n",
      "Epoch 10/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.2676 - accuracy: 0.9249 - val_loss: 1.2033 - val_accuracy: 0.7283\n",
      "Epoch 11/20\n",
      "248/248 [==============================] - 368s 1s/step - loss: 0.2048 - accuracy: 0.9419 - val_loss: 4.1206 - val_accuracy: 0.6015\n",
      "Epoch 12/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.1967 - accuracy: 0.9457 - val_loss: 1.2254 - val_accuracy: 0.8152\n",
      "Epoch 13/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.3106 - accuracy: 0.9190 - val_loss: 0.6045 - val_accuracy: 0.8523\n",
      "Epoch 14/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.2325 - accuracy: 0.9380 - val_loss: 0.7007 - val_accuracy: 0.8439\n",
      "Epoch 15/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.2574 - accuracy: 0.9427 - val_loss: 3.9236 - val_accuracy: 0.6351\n",
      "Epoch 16/20\n",
      "248/248 [==============================] - 368s 1s/step - loss: 0.2345 - accuracy: 0.9448 - val_loss: 0.6227 - val_accuracy: 0.8641\n",
      "Epoch 17/20\n",
      "248/248 [==============================] - 372s 1s/step - loss: 0.1463 - accuracy: 0.9590 - val_loss: 0.9622 - val_accuracy: 0.8561\n",
      "Epoch 18/20\n",
      "248/248 [==============================] - 370s 1s/step - loss: 0.1266 - accuracy: 0.9670 - val_loss: 0.9732 - val_accuracy: 0.8184\n",
      "Epoch 19/20\n",
      "248/248 [==============================] - 374s 2s/step - loss: 0.1259 - accuracy: 0.9650 - val_loss: 3.7059 - val_accuracy: 0.7056\n",
      "Epoch 20/20\n",
      "248/248 [==============================] - 371s 1s/step - loss: 0.1219 - accuracy: 0.9670 - val_loss: 1.9518 - val_accuracy: 0.7568\n"
     ]
    }
   ],
   "source": [
    "#AlexNet for Plant identification with MinMax norm normalization\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, MaxPool2D\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model_alex1 = Sequential()\n",
    "\n",
    "model_alex1.add(Conv2D(filters=96, kernel_size=(11, 11), \n",
    "                        strides=(4, 4), activation=\"relu\", \n",
    "                        input_shape=(227, 227, 3)))\n",
    "model_alex1.add(BatchNormalization())\n",
    "model_alex1.add(MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n",
    "model_alex1.add(Conv2D(filters=256, kernel_size=(5, 5), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex1.add(BatchNormalization())\n",
    "model_alex1.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model_alex1.add(Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex1.add(BatchNormalization())\n",
    "model_alex1.add(Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex1.add(BatchNormalization())\n",
    "model_alex1.add(Conv2D(filters=256, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex1.add(BatchNormalization())\n",
    "model_alex1.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model_alex1.add(Flatten())\n",
    "model_alex1.add(Dense(4096, activation=\"relu\"))\n",
    "model_alex1.add(Dropout(0.5))\n",
    "model_alex1.add(Dense(9, activation=\"softmax\"))\n",
    "\n",
    "# model_alex1.compile(loss='sparse_categorical_crossentropy', \n",
    "#               optimizer=tf.optimizers.SGD(lr=0.001), \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "#model_alex1.summary()\n",
    "\n",
    "model_alex1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_alex1_history = model_alex1.fit(X_train, y_train, batch_size=64, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86e71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 25s 198ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.90      0.69       449\n",
      "         1.0       0.83      0.43      0.57       258\n",
      "         2.0       0.99      0.96      0.98       486\n",
      "         3.0       1.00      0.87      0.93       503\n",
      "         4.0       0.51      1.00      0.68       253\n",
      "         5.0       0.42      0.98      0.59       252\n",
      "         6.0       0.93      0.18      0.30       363\n",
      "         7.0       0.99      0.71      0.83       235\n",
      "         8.0       0.97      0.73      0.83      1161\n",
      "\n",
      "    accuracy                           0.76      3960\n",
      "   macro avg       0.80      0.75      0.71      3960\n",
      "weighted avg       0.85      0.76      0.75      3960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>402</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>34</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8\n",
       "Real                                                 \n",
       "0.0        402    8    2    0   29    8   0    0    0\n",
       "1.0         34  112    0    0   55   57   0    0    0\n",
       "2.0          6    0  468    0   10    2   0    0    0\n",
       "3.0         32    0    0  438    7   25   0    0    1\n",
       "4.0          1    0    0    0  252    0   0    0    0\n",
       "5.0          2    0    0    0    3  247   0    0    0\n",
       "6.0         68    7    1    0    8  191  64    1   23\n",
       "7.0         58    1    1    0    2    3   0  168    2\n",
       "8.0        120    7    1    1  124   56   5    1  846"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AlexNet MinMax norm regularization\n",
    "# predicting the the plants of the test set\n",
    "y_pred_model_alex1 = model_alex1.predict(X_test)\n",
    "\n",
    "# getting the Plant with highest probabilty \n",
    "y_pred = np.argmax(y_pred_model_alex1, axis=1)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e408fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset as (227,227,3) for AlexNet model with MinMax binary normalization\n",
    "\n",
    "#convert the images and save them in a list. \n",
    "X = [] # stores the image \n",
    "y = [] # stores the plants class\n",
    "diseases = [] #stores the diseases of the plants\n",
    "\n",
    "for folder_name, _,filenames in os.walk(image_path):\n",
    "    if folder_name !=\"dataset/color\" and '.DS_Store' not in filenames:\n",
    "        for file in filenames:\n",
    "            if file != 'desktop.ini':\n",
    "                file_path = folder_name +\"/\"+ file\n",
    "                image = Image.open(file_path)\n",
    "                image = image.convert('RGB')\n",
    "                image = np.array(image.resize((227,227)))\n",
    "                ret, thresh = cv2.threshold(image,140,255,cv2.THRESH_BINARY)\n",
    "                image = cv2.normalize(thresh, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                X.append(image)\n",
    "                y.append(os.path.basename(folder_name.split('\\\\')[1].split('___')[0]))\n",
    "                diseases.append(os.path.basename(folder_name.split('\\\\')[1]))\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "X = np.array(X).astype('float32')\n",
    "\n",
    "# Encoding the labels\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y_le = le.fit_transform(y)\n",
    "\n",
    "y_le = np.array(y_le).astype('float32')\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_le, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad4fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "248/248 [==============================] - 351s 1s/step - loss: 6.1867 - accuracy: 0.4778 - val_loss: 2.1431 - val_accuracy: 0.5222\n",
      "Epoch 2/30\n",
      "248/248 [==============================] - 339s 1s/step - loss: 1.0076 - accuracy: 0.6631 - val_loss: 1.1655 - val_accuracy: 0.6391\n",
      "Epoch 3/30\n",
      "248/248 [==============================] - 340s 1s/step - loss: 0.7819 - accuracy: 0.7331 - val_loss: 0.8958 - val_accuracy: 0.7078\n",
      "Epoch 4/30\n",
      "248/248 [==============================] - 339s 1s/step - loss: 0.6596 - accuracy: 0.7823 - val_loss: 0.6311 - val_accuracy: 0.7975\n",
      "Epoch 5/30\n",
      "248/248 [==============================] - 340s 1s/step - loss: 0.6065 - accuracy: 0.8015 - val_loss: 0.7494 - val_accuracy: 0.7682\n",
      "Epoch 6/30\n",
      "248/248 [==============================] - 339s 1s/step - loss: 0.5299 - accuracy: 0.8278 - val_loss: 0.4836 - val_accuracy: 0.8462\n",
      "Epoch 7/30\n",
      "248/248 [==============================] - 338s 1s/step - loss: 0.4735 - accuracy: 0.8507 - val_loss: 0.6538 - val_accuracy: 0.8023\n",
      "Epoch 8/30\n",
      "248/248 [==============================] - 332s 1s/step - loss: 0.3952 - accuracy: 0.8710 - val_loss: 0.5434 - val_accuracy: 0.8331\n",
      "Epoch 9/30\n",
      "248/248 [==============================] - 339s 1s/step - loss: 0.3669 - accuracy: 0.8821 - val_loss: 0.7557 - val_accuracy: 0.8114\n",
      "Epoch 10/30\n",
      "248/248 [==============================] - 337s 1s/step - loss: 0.3586 - accuracy: 0.8888 - val_loss: 0.9032 - val_accuracy: 0.7952\n",
      "Epoch 11/30\n",
      "248/248 [==============================] - 343s 1s/step - loss: 0.3476 - accuracy: 0.8954 - val_loss: 0.6747 - val_accuracy: 0.8179\n",
      "Epoch 12/30\n",
      "248/248 [==============================] - 341s 1s/step - loss: 0.3780 - accuracy: 0.8873 - val_loss: 0.5555 - val_accuracy: 0.8540\n",
      "Epoch 13/30\n",
      "248/248 [==============================] - 343s 1s/step - loss: 0.3569 - accuracy: 0.8943 - val_loss: 0.5635 - val_accuracy: 0.8492\n",
      "Epoch 14/30\n",
      "248/248 [==============================] - 340s 1s/step - loss: 0.3041 - accuracy: 0.9080 - val_loss: 0.4091 - val_accuracy: 0.8783\n",
      "Epoch 15/30\n",
      "248/248 [==============================] - 341s 1s/step - loss: 0.5055 - accuracy: 0.8756 - val_loss: 1.0543 - val_accuracy: 0.6515\n",
      "Epoch 16/30\n",
      "248/248 [==============================] - 340s 1s/step - loss: 0.3587 - accuracy: 0.8977 - val_loss: 0.3580 - val_accuracy: 0.9030\n",
      "Epoch 17/30\n",
      "248/248 [==============================] - 333s 1s/step - loss: 0.2681 - accuracy: 0.9183 - val_loss: 0.5224 - val_accuracy: 0.8717\n",
      "Epoch 18/30\n",
      "248/248 [==============================] - 335s 1s/step - loss: 0.1994 - accuracy: 0.9393 - val_loss: 0.4084 - val_accuracy: 0.8919\n",
      "Epoch 19/30\n",
      "248/248 [==============================] - 341s 1s/step - loss: 0.1801 - accuracy: 0.9456 - val_loss: 0.5643 - val_accuracy: 0.8760\n",
      "Epoch 20/30\n",
      "248/248 [==============================] - 339s 1s/step - loss: 0.1852 - accuracy: 0.9451 - val_loss: 0.5792 - val_accuracy: 0.8682\n",
      "Epoch 21/30\n",
      "248/248 [==============================] - 338s 1s/step - loss: 0.2954 - accuracy: 0.9242 - val_loss: 0.5952 - val_accuracy: 0.8702\n",
      "Epoch 22/30\n",
      "248/248 [==============================] - 341s 1s/step - loss: 0.2012 - accuracy: 0.9441 - val_loss: 0.5354 - val_accuracy: 0.8927\n",
      "Epoch 23/30\n",
      "248/248 [==============================] - 338s 1s/step - loss: 0.1975 - accuracy: 0.9446 - val_loss: 0.6732 - val_accuracy: 0.8705\n",
      "Epoch 24/30\n",
      "248/248 [==============================] - 341s 1s/step - loss: 0.1579 - accuracy: 0.9549 - val_loss: 0.4247 - val_accuracy: 0.9043\n",
      "Epoch 25/30\n",
      "248/248 [==============================] - 338s 1s/step - loss: 0.1291 - accuracy: 0.9626 - val_loss: 0.4082 - val_accuracy: 0.9116\n",
      "Epoch 26/30\n",
      "248/248 [==============================] - 342s 1s/step - loss: 0.1644 - accuracy: 0.9557 - val_loss: 0.4709 - val_accuracy: 0.9124\n",
      "Epoch 27/30\n",
      "248/248 [==============================] - 338s 1s/step - loss: 0.1210 - accuracy: 0.9657 - val_loss: 0.5506 - val_accuracy: 0.9025\n",
      "Epoch 28/30\n",
      "248/248 [==============================] - 336s 1s/step - loss: 0.1594 - accuracy: 0.9559 - val_loss: 0.8325 - val_accuracy: 0.8737\n",
      "Epoch 29/30\n",
      "248/248 [==============================] - 334s 1s/step - loss: 0.2077 - accuracy: 0.9478 - val_loss: 0.3979 - val_accuracy: 0.9179\n",
      "Epoch 30/30\n",
      "248/248 [==============================] - 336s 1s/step - loss: 0.1356 - accuracy: 0.9622 - val_loss: 0.4419 - val_accuracy: 0.9189\n"
     ]
    }
   ],
   "source": [
    "# AlexNet for Plant identification with MinMax norm binary normalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, MaxPool2D\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model_alex2 = Sequential()\n",
    "\n",
    "model_alex2.add(Conv2D(filters=96, kernel_size=(11, 11), \n",
    "                        strides=(4, 4), activation=\"relu\", \n",
    "                        input_shape=(227, 227, 3)))\n",
    "model_alex2.add(BatchNormalization())\n",
    "model_alex2.add(MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n",
    "model_alex2.add(Conv2D(filters=256, kernel_size=(5, 5), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex2.add(BatchNormalization())\n",
    "model_alex2.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model_alex2.add(Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex2.add(BatchNormalization())\n",
    "model_alex2.add(Conv2D(filters=384, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex2.add(BatchNormalization())\n",
    "model_alex2.add(Conv2D(filters=256, kernel_size=(3, 3), \n",
    "                        strides=(1, 1), activation=\"relu\", \n",
    "                        padding=\"same\"))\n",
    "model_alex2.add(BatchNormalization())\n",
    "model_alex2.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model_alex2.add(Flatten())\n",
    "model_alex2.add(Dense(4096, activation=\"relu\"))\n",
    "model_alex2.add(Dropout(0.5))\n",
    "model_alex2.add(Dense(9, activation=\"softmax\"))\n",
    "\n",
    "# model_alex2.compile(loss='sparse_categorical_crossentropy', \n",
    "#               optimizer=tf.optimizers.SGD(lr=0.001), \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "#model_alex2.summary()\n",
    "\n",
    "model_alex2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_alex2_history = model_alex2.fit(X_train, y_train, batch_size=64, epochs=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ccea107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 24s 193ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.86       449\n",
      "         1.0       0.97      0.91      0.94       258\n",
      "         2.0       0.98      0.96      0.97       486\n",
      "         3.0       0.98      0.98      0.98       503\n",
      "         4.0       0.85      0.92      0.88       253\n",
      "         5.0       0.92      0.90      0.91       252\n",
      "         6.0       0.95      0.79      0.86       363\n",
      "         7.0       0.97      0.88      0.92       235\n",
      "         8.0       0.90      0.94      0.92      1161\n",
      "\n",
      "    accuracy                           0.92      3960\n",
      "   macro avg       0.93      0.91      0.92      3960\n",
      "weighted avg       0.92      0.92      0.92      3960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>466</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>206</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7     8\n",
       "Real                                                   \n",
       "0.0        404    1    2    0   11    4    3    4    20\n",
       "1.0          6  236    1    1    0    3    0    0    11\n",
       "2.0          9    0  466    0    3    0    0    0     8\n",
       "3.0          1    0    0  493    0    0    0    1     8\n",
       "4.0          6    0    0    0  232    0    0    0    15\n",
       "5.0          5    0    0    0    8  226    1    1    11\n",
       "6.0         20    1    1    2    3    7  287    0    42\n",
       "7.0         10    0    6    4    1    0    1  206     7\n",
       "8.0         32    5    0    5   14    6    9    1  1089"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AlexNet with MinMax norm binary normalization\n",
    "# predicting the the plants of the test set\n",
    "y_pred_model_alex2 = model_alex2.predict(X_test)\n",
    "\n",
    "# getting the Plant with highest probabilty \n",
    "y_pred = np.argmax(y_pred_model_alex2, axis=1)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df8ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
