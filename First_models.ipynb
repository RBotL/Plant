{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337b7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image \n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66789f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'dataset/color'\n",
    "\n",
    "#convert the images and save them in a array. \n",
    "color_X = []\n",
    "color_y = []\n",
    "for folder_name, _,filenames in os.walk(image_path):\n",
    "    if folder_name !=\"dataset/color\" and '.DS_Store' not in filenames:\n",
    "        for file in filenames:\n",
    "            if file != 'desktop.ini':\n",
    "                file_path = folder_name +\"/\"+ file\n",
    "                image = Image.open(file_path)\n",
    "                image = image.convert('RGB')\n",
    "                #image = image.resize((width, height))\n",
    "                color_X.append(np.array(image))\n",
    "                color_y.append(os.path.basename(folder_name))\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5320362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the images and labels into arrays\n",
    "color_X_array = np.array(color_X)\n",
    "color_y_array  = np.array(color_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84ff116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(color_X_array, color_y_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4ae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a small portion of the set for faster training 20% of the total data\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(X_test, y_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9768875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(544, 38)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7c7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label into integers\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y_train_le = le.fit_transform(y_train_small)\n",
    "y_test_le = le.transform(y_test_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d46b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of the labels\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train_re = y_train_le.reshape(-1, 1)\n",
    "y_test_re = y_test_le.reshape(-1, 1)\n",
    "y_train_one = onehot_encoder.fit_transform(y_train_re)\n",
    "y_test_one = onehot_encoder.transform(y_test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7bb8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: CNN 2 convolution layers\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(64,kernel_size=(3,3),activation=\"relu\", padding=\"same\",\n",
    "                  kernel_regularizer=regularizers.l2(0.00001), input_shape=(256, 256, 3)))\n",
    "model1.add(MaxPooling2D(pool_size=6, strides=2, padding='same'))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=6, strides=2, padding='same'))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128,activation=\"relu\")) \n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(38,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "139a969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "68/68 [==============================] - 65s 941ms/step - loss: 3.1016 - accuracy: 0.1524 - val_loss: 3.3029 - val_accuracy: 0.1121\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 63s 930ms/step - loss: 3.0704 - accuracy: 0.1469 - val_loss: 3.3012 - val_accuracy: 0.1140\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 63s 930ms/step - loss: 3.0206 - accuracy: 0.1680 - val_loss: 3.2893 - val_accuracy: 0.1213\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 2203s 33s/step - loss: 2.9912 - accuracy: 0.1768 - val_loss: 3.2778 - val_accuracy: 0.1250\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 63s 925ms/step - loss: 2.9328 - accuracy: 0.1934 - val_loss: 3.3284 - val_accuracy: 0.1140\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 62s 907ms/step - loss: 2.8967 - accuracy: 0.1948 - val_loss: 3.3717 - val_accuracy: 0.1324\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 62s 918ms/step - loss: 2.8186 - accuracy: 0.2284 - val_loss: 3.3441 - val_accuracy: 0.1324\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 61s 900ms/step - loss: 2.7738 - accuracy: 0.2413 - val_loss: 3.4523 - val_accuracy: 0.1507\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 62s 910ms/step - loss: 2.6982 - accuracy: 0.2523 - val_loss: 3.4267 - val_accuracy: 0.1397\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 63s 929ms/step - loss: 2.6444 - accuracy: 0.2693 - val_loss: 3.6458 - val_accuracy: 0.1507\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit Model 1\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1_history = model1.fit(X_train_small, y_train_one, batch_size=128, epochs=10, validation_data=(X_test_small, y_test_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b714a57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "136/136 [==============================] - 367s 3s/step - loss: 1065.1208 - accuracy: 0.1380 - val_loss: 3.1113 - val_accuracy: 0.1758\n",
      "Epoch 2/20\n",
      "136/136 [==============================] - 368s 3s/step - loss: 2.2649 - accuracy: 0.4101 - val_loss: 2.8050 - val_accuracy: 0.2876\n",
      "Epoch 3/20\n",
      "136/136 [==============================] - 368s 3s/step - loss: 1.0936 - accuracy: 0.7081 - val_loss: 3.1836 - val_accuracy: 0.3143\n",
      "Epoch 4/20\n",
      "136/136 [==============================] - 368s 3s/step - loss: 0.5907 - accuracy: 0.8451 - val_loss: 5.4903 - val_accuracy: 0.3645\n",
      "Epoch 5/20\n",
      "136/136 [==============================] - 366s 3s/step - loss: 0.4937 - accuracy: 0.8804 - val_loss: 5.4495 - val_accuracy: 0.3083\n",
      "Epoch 6/20\n",
      "136/136 [==============================] - 365s 3s/step - loss: 0.5211 - accuracy: 0.8828 - val_loss: 6.1651 - val_accuracy: 0.3507\n",
      "Epoch 7/20\n",
      "136/136 [==============================] - 369s 3s/step - loss: 0.3184 - accuracy: 0.9251 - val_loss: 6.9071 - val_accuracy: 0.3631\n",
      "Epoch 8/20\n",
      "136/136 [==============================] - 375s 3s/step - loss: 0.3375 - accuracy: 0.9260 - val_loss: 6.9825 - val_accuracy: 0.3364\n",
      "Epoch 9/20\n",
      "136/136 [==============================] - 370s 3s/step - loss: 0.2572 - accuracy: 0.9416 - val_loss: 8.8793 - val_accuracy: 0.3525\n",
      "Epoch 10/20\n",
      "136/136 [==============================] - 370s 3s/step - loss: 0.2239 - accuracy: 0.9515 - val_loss: 8.3216 - val_accuracy: 0.3741\n",
      "Epoch 11/20\n",
      "136/136 [==============================] - 372s 3s/step - loss: 0.2601 - accuracy: 0.9407 - val_loss: 8.3094 - val_accuracy: 0.3461\n",
      "Epoch 12/20\n",
      "136/136 [==============================] - 372s 3s/step - loss: 0.1602 - accuracy: 0.9649 - val_loss: 10.2915 - val_accuracy: 0.3741\n",
      "Epoch 13/20\n",
      "136/136 [==============================] - 375s 3s/step - loss: 0.1717 - accuracy: 0.9652 - val_loss: 10.5539 - val_accuracy: 0.3502\n",
      "Epoch 14/20\n",
      "136/136 [==============================] - 370s 3s/step - loss: 0.1628 - accuracy: 0.9625 - val_loss: 9.9181 - val_accuracy: 0.3603\n",
      "Epoch 15/20\n",
      "136/136 [==============================] - 370s 3s/step - loss: 0.1573 - accuracy: 0.9692 - val_loss: 11.6824 - val_accuracy: 0.3709\n",
      "Epoch 16/20\n",
      "136/136 [==============================] - 366s 3s/step - loss: 0.1615 - accuracy: 0.9667 - val_loss: 12.4288 - val_accuracy: 0.3470\n",
      "Epoch 17/20\n",
      "136/136 [==============================] - 368s 3s/step - loss: 0.1335 - accuracy: 0.9705 - val_loss: 11.6190 - val_accuracy: 0.3659\n",
      "Epoch 18/20\n",
      "136/136 [==============================] - 368s 3s/step - loss: 0.1094 - accuracy: 0.9757 - val_loss: 13.1429 - val_accuracy: 0.3801\n",
      "Epoch 19/20\n",
      "136/136 [==============================] - 374s 3s/step - loss: 0.1323 - accuracy: 0.9725 - val_loss: 14.2457 - val_accuracy: 0.3778\n",
      "Epoch 20/20\n",
      "136/136 [==============================] - 371s 3s/step - loss: 0.1036 - accuracy: 0.9800 - val_loss: 13.2345 - val_accuracy: 0.3879\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "# Model 2: CNN 1 convolution layer\n",
    "\n",
    "model_conv = Sequential()\n",
    "\n",
    "model_conv.add(Conv2D(filters = 64,\n",
    "                     input_shape = (256,256,3),\n",
    "                     kernel_size = (5,5),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "\n",
    "model_conv.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model_conv.add(Dropout(rate = 0.2))\n",
    "\n",
    "model_conv.add(Flatten())\n",
    "\n",
    "model_conv.add(Dense(units = 256,\n",
    "                    activation = 'relu'))\n",
    "\n",
    "model_conv.add(Dense(units = 38,\n",
    "                     activation='softmax'))\n",
    "\n",
    "model_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modelconv_history = model_conv.fit(X_train_small, y_train_one, batch_size=64, epochs=20, validation_data=(X_test_small, y_test_one))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee3b7eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "136/136 [==============================] - 477s 3s/step - loss: 62.2484 - accuracy: 0.1140 - val_loss: 3.4019 - val_accuracy: 0.1275\n",
      "Epoch 2/20\n",
      "136/136 [==============================] - 4378s 32s/step - loss: 3.3187 - accuracy: 0.1214 - val_loss: 3.2661 - val_accuracy: 0.1238\n",
      "Epoch 3/20\n",
      "136/136 [==============================] - 471s 3s/step - loss: 3.2191 - accuracy: 0.1296 - val_loss: 3.2887 - val_accuracy: 0.1431\n",
      "Epoch 4/20\n",
      "136/136 [==============================] - 3393s 25s/step - loss: 3.1130 - accuracy: 0.1609 - val_loss: 3.2397 - val_accuracy: 0.1362\n",
      "Epoch 5/20\n",
      "136/136 [==============================] - 470s 3s/step - loss: 2.8742 - accuracy: 0.2179 - val_loss: 3.2624 - val_accuracy: 0.1440\n",
      "Epoch 6/20\n",
      "136/136 [==============================] - 467s 3s/step - loss: 2.6669 - accuracy: 0.2682 - val_loss: 3.4377 - val_accuracy: 0.1445\n",
      "Epoch 7/20\n",
      "136/136 [==============================] - 472s 3s/step - loss: 2.4726 - accuracy: 0.3189 - val_loss: 3.5772 - val_accuracy: 0.1450\n",
      "Epoch 8/20\n",
      "136/136 [==============================] - 487s 4s/step - loss: 2.3671 - accuracy: 0.3501 - val_loss: 4.2777 - val_accuracy: 0.1601\n",
      "Epoch 9/20\n",
      "136/136 [==============================] - 492s 4s/step - loss: 2.2172 - accuracy: 0.3919 - val_loss: 5.1153 - val_accuracy: 0.1675\n",
      "Epoch 10/20\n",
      "136/136 [==============================] - 492s 4s/step - loss: 2.0971 - accuracy: 0.4247 - val_loss: 4.8753 - val_accuracy: 0.1652\n",
      "Epoch 11/20\n",
      "136/136 [==============================] - 494s 4s/step - loss: 2.0610 - accuracy: 0.4400 - val_loss: 4.5881 - val_accuracy: 0.1652\n",
      "Epoch 12/20\n",
      "136/136 [==============================] - 494s 4s/step - loss: 2.2607 - accuracy: 0.4529 - val_loss: 5.6747 - val_accuracy: 0.1643\n",
      "Epoch 13/20\n",
      "136/136 [==============================] - 509s 4s/step - loss: 1.9246 - accuracy: 0.4751 - val_loss: 5.4976 - val_accuracy: 0.1730\n",
      "Epoch 14/20\n",
      "136/136 [==============================] - 511s 4s/step - loss: 1.8260 - accuracy: 0.4994 - val_loss: 5.5022 - val_accuracy: 0.1684\n",
      "Epoch 15/20\n",
      "136/136 [==============================] - 496s 4s/step - loss: 1.8061 - accuracy: 0.5081 - val_loss: 6.0306 - val_accuracy: 0.1684\n",
      "Epoch 16/20\n",
      "136/136 [==============================] - 494s 4s/step - loss: 1.7278 - accuracy: 0.5252 - val_loss: 6.6204 - val_accuracy: 0.1758\n",
      "Epoch 17/20\n",
      "136/136 [==============================] - 492s 4s/step - loss: 1.6697 - accuracy: 0.5436 - val_loss: 6.8631 - val_accuracy: 0.1712\n",
      "Epoch 18/20\n",
      "136/136 [==============================] - 492s 4s/step - loss: 1.7028 - accuracy: 0.5372 - val_loss: 7.3749 - val_accuracy: 0.1712\n",
      "Epoch 19/20\n",
      "136/136 [==============================] - 493s 4s/step - loss: 1.5962 - accuracy: 0.5626 - val_loss: 8.1724 - val_accuracy: 0.1726\n",
      "Epoch 20/20\n",
      "136/136 [==============================] - 493s 4s/step - loss: 1.6101 - accuracy: 0.5622 - val_loss: 9.1459 - val_accuracy: 0.1717\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "# Model 3:  CNN 1 convolution layer\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(filters = 64,\n",
    "                     input_shape = (256,256,3),\n",
    "                     kernel_size = (5,5),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model1.add(Dropout(rate = 0.2))\n",
    "\n",
    "model1.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(units = 128,\n",
    "                    activation = 'relu'))\n",
    "\n",
    "model1.add(Dense(units = 38,\n",
    "                     activation='softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model1_history = model1.fit(X_train_small, y_train_one, batch_size=64, epochs=20, validation_data=(X_test_small, y_test_one))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb0a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
